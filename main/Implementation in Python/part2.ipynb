{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-collective",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install -U som-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-brazil",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install sklearn-som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-experiment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "christian-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import sys\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reliable-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_som.som import SOM as SOM_sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minor-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from somlearn import SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "young-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import random_noise\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compatible-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def read_dataset(self):\n",
    "        directory = \"Dataset/\"\n",
    "        train_data = []\n",
    "        test_data = []\n",
    "        train_label = [] \n",
    "        test_label = []\n",
    "\n",
    "        for i in range(0,10):\n",
    "            data_dir = directory + str(i) + '/'\n",
    "\n",
    "            # bipolar one hot lable\n",
    "            lable = -1 * np.ones((100, 19), dtype=int)     \n",
    "            lable[:, i] = 1\n",
    "\n",
    "            images = self.read_image(data_dir)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(images, lable, test_size=0.20, random_state=42)\n",
    "\n",
    "            train_data.append(X_train)\n",
    "            test_data.append(X_test)\n",
    "            train_label.append(y_train)\n",
    "            test_label.append(y_test)\n",
    "\n",
    "        maths = ['add', 'dec', 'div', 'eq', 'mul', 'sub', 'x', 'y', 'z']\n",
    "        for i, op in enumerate(maths):\n",
    "            data_dir = directory + op + '/'\n",
    "\n",
    "            # bipolar one hot lable\n",
    "            lable = -1 * np.ones((100, 19), dtype=int)     \n",
    "            lable[:, i+10] = 1\n",
    "\n",
    "            images = self.read_image(data_dir)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(images, lable, test_size=0.20, random_state=42)\n",
    "\n",
    "            train_data.append(X_train)\n",
    "            test_data.append(X_test)\n",
    "            train_label.append(y_train)\n",
    "            test_label.append(y_test)\n",
    "\n",
    "        train_data = np.concatenate(train_data, axis=0)\n",
    "        test_data = np.concatenate(test_data, axis=0)\n",
    "        train_label = np.concatenate(train_label, axis=0)\n",
    "        test_label = np.concatenate(test_label, axis=0)\n",
    "\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.train_label = train_label\n",
    "        self.test_label = test_label\n",
    "\n",
    "        X_train, y_train = shuffle(self.train_data, self.train_label, random_state=0)\n",
    "        self.train_data_shuffle = X_train\n",
    "        self.train_label_shuffle = y_train\n",
    "        \n",
    "        \n",
    "        X_test, y_test = shuffle(self.test_data, self.test_label, random_state=0)\n",
    "        self.test_data_shuffle = X_test\n",
    "        self.test_label_shuffle = y_test\n",
    "        \n",
    "    def read_image(self, directory):\n",
    "        path = os.path.join(directory)\n",
    "        images = []\n",
    "        img_size = 100\n",
    "        for img in os.listdir(path):\n",
    "            img_array = cv.imread(os.path.join(path,img), cv.IMREAD_GRAYSCALE)\n",
    "            if img_array is not None:\n",
    "                new_image = cv.resize(img_array, (img_size, img_size))\n",
    "                images.append(new_image / 255)\n",
    "        \n",
    "        images = np.array(images)    \n",
    "        flatten_img = images.reshape(100,(img_size*img_size))\n",
    "        return flatten_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-ceiling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "second-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOM_Mine():\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "        self.cluster_label = None\n",
    "    \n",
    "    def set_cluster_label(self, y, labels):\n",
    "        list_mode = []\n",
    "        for inde_la in range(self.num_nerons):\n",
    "            index_c0 = np.argwhere(labels == inde_la).reshape(1, -1)\n",
    "\n",
    "            if self.single_label == False:\n",
    "                true_class = [np.argmax(y[i]) for i in index_c0[0]]\n",
    "            else:\n",
    "                true_class = [y[i] for i in index_c0[0]]\n",
    "        \n",
    "            # majority vote\n",
    "            list_mode.append(Counter(true_class).most_common(1)[0][0])\n",
    "        \n",
    "        return np.array(list_mode)\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, num_col = 8, num_row = 5, single_label = False):\n",
    "        self.num_classes = 19\n",
    "        self.single_label = single_label\n",
    "        self.num_nerons = num_col * num_row\n",
    "        \n",
    "        self.som = SOM(n_columns = num_col, n_rows = num_row, random_state = 1)\n",
    "        labels = self.som.fit_predict(X, epochs = 200, scale0 = 0.01)\n",
    "        \n",
    "        dic_labels = sorted(Counter(labels).items())\n",
    "        assert len(dic_labels) == self.num_nerons\n",
    "        \n",
    "        # weights\n",
    "        self.weights = self.som.algorithm_.codebook.reshape(self.num_nerons, -1)\n",
    "        \n",
    "        # cluster labels\n",
    "        self.cluster_label = self.set_cluster_label(y, labels)\n",
    "        \n",
    "        return self.weights, self.cluster_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "industrial-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LVQ():\n",
    "    def __init__(self, initial_codebook, cluster_label, alpha = 1e-4):\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.weights = initial_codebook  # (num_nerons, 100*100)\n",
    "        self.cluster_label = cluster_label  # (num_nerons,)\n",
    "        \n",
    "        self.num_nerons = self.weights.shape[0]\n",
    "        assert self.num_nerons == len(self.cluster_label)\n",
    "\n",
    "        \n",
    "    def euclidean_distance(self, x, w):\n",
    "        # x is (num_nerons, 100*100)\n",
    "        # w is (num_nerons, 100*100)\n",
    "        # output is (num_nerons,)\n",
    "        \n",
    "        distance = np.zeros(self.num_nerons)\n",
    "        for i in range(len(x)):\n",
    "            distance[i] = np.sum((x[i] - w[i])**2)\n",
    "        return distance\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y_, max_epoch = 200, decrese_alpha = True, single_label = False):\n",
    "        self.single_label = single_label\n",
    "        epoch = 0\n",
    "        flag = True\n",
    "        while flag:\n",
    "            print('epoch', epoch)\n",
    "            \n",
    "            # decrese alpha\n",
    "            if decrese_alpha:\n",
    "#                 rate = self.alpha * (1.0-(epoch/float(max_epoch)))\n",
    "                if epoch % 100 == 0 and epoch != 0:\n",
    "                    rate = self.alpha / 10\n",
    "                else:\n",
    "                    rate = self.alpha\n",
    "            else:\n",
    "                rate = self.alpha\n",
    "               \n",
    "            sames_la = 0\n",
    "            not_sames = 0\n",
    "            for f_img, label_ in zip(X, y_):\n",
    "                image = f_img.reshape(1, -1)\n",
    "                \n",
    "                if self.single_label == False:\n",
    "                    label = label_.reshape(19, 1)\n",
    "                    label = label.astype(float)\n",
    "                    t = np.argmax(label)\n",
    "                else:\n",
    "                    t = label_\n",
    "                \n",
    "                one_vector = np.ones((self.num_nerons, 1))\n",
    "                eu_dis = self.euclidean_distance(one_vector @ image, self.weights)\n",
    "                \n",
    "                k = np.argmin(eu_dis)\n",
    "                \n",
    "                \n",
    "                # update\n",
    "                delta = rate * (image - self.weights[k])\n",
    "                                                \n",
    "                if t == self.cluster_label[k]:         \n",
    "                    sames_la += 1\n",
    "                    self.weights[k] += delta[0]\n",
    "                else:\n",
    "                    not_sames += 1\n",
    "                    self.weights[k] -= delta[0]\n",
    "                \n",
    "            \n",
    "            if epoch < max_epoch:\n",
    "                epoch += 1\n",
    "                flag = True\n",
    "            else:\n",
    "                flag = False\n",
    "    \n",
    "    \n",
    "    def predict(self, x_img):\n",
    "        image = x_img.reshape(1 , -1)\n",
    "        \n",
    "        one_vector = np.ones((self.num_nerons, 1))\n",
    "        eu_dis = self.euclidean_distance(one_vector @ image, self.weights)\n",
    "\n",
    "        k = np.argmin(eu_dis)\n",
    "\n",
    "        return self.cluster_label[k]\n",
    "    \n",
    "    \n",
    "    def test(self, X, y_):\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for f_img, label in zip(X, y_):\n",
    "            class_predict = self.predict(f_img)\n",
    "            y_pred.append(class_predict)\n",
    "            \n",
    "            if self.single_label == False:\n",
    "                class_true = np.argmax(label)\n",
    "            else:\n",
    "                class_true = label\n",
    "                \n",
    "            y_true.append(class_true)\n",
    "            \n",
    "        self.y_true = y_true\n",
    "        self.y_pred = y_pred\n",
    "        print('accuracy: ',accuracy_score(self.y_true, self.y_pred)* 100)\n",
    "        print('\\n')\n",
    "        print('precision: ',precision_score(self.y_true, self.y_pred, average=None, zero_division = 0) * 100)\n",
    "        print('***')\n",
    "        print('precision: ',precision_score(self.y_true, self.y_pred, average='macro', zero_division = 0) * 100)\n",
    "        print('\\n')\n",
    "        print('recall: ', recall_score(self.y_true, self.y_pred, average=None) * 100)\n",
    "        print('***')\n",
    "        print('recall: ', recall_score(self.y_true, self.y_pred, average='macro') * 100)\n",
    "        \n",
    "        return self.y_true, self.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-slovakia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-kennedy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "canadian-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset.read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "antique-specific",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight shape (50, 10000)\n",
      "cluser shape (50,)\n",
      "cluster [14  8  8 12 12 18 17  5  6 15  9  1  5 16 18  8  1 16 17  0  7 15 15 16\n",
      " 16  7 11  2 17 18 11 11  2 17 13  0  5  5 13 13  0  2  0  6 10  7  2  4\n",
      " 10 13]\n"
     ]
    }
   ],
   "source": [
    "Mine_SOM = SOM_Mine()\n",
    "we, clus = Mine_SOM.fit(dataset.train_data_shuffle, dataset.train_label_shuffle, num_col = 10, num_row = 5)\n",
    "print('weight shape', we.shape)\n",
    "print('cluser shape', clus.shape)\n",
    "print('cluster', clus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "altered-paper",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(sorted(clus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-boundary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "partial-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weight = copy.deepcopy(we)\n",
    "init_clus = copy.deepcopy(clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-johns",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lvq = LVQ(init_weight, init_clus, alpha = 1e-3)\n",
    "lvq.fit(dataset.train_data_shuffle, dataset.train_label_shuffle, max_epoch = 1, decrese_alpha =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "latest-cowboy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "accuracy:  40.526315789473685\n",
      "\n",
      "\n",
      "precision:  [11.76470588 32.35294118 31.57894737  0.         40.         41.66666667\n",
      " 20.         23.80952381 29.16666667 50.         62.5        53.33333333\n",
      " 50.         46.15384615 56.         38.0952381  50.         45.83333333\n",
      " 40.74074074]\n",
      "***\n",
      "precision:  38.05241806455755\n",
      "\n",
      "\n",
      "recall:  [10. 55. 30.  0. 40. 50. 10. 25. 35. 35. 50. 80. 35. 60. 70. 40. 35. 55.\n",
      " 55.]\n",
      "***\n",
      "recall:  40.526315789473685\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "\n",
      "\n",
      "Train\n",
      "accuracy:  57.10526315789474\n",
      "\n",
      "\n",
      "precision:  [57.53424658 47.32142857 62.85714286  0.         52.72727273 66.31578947\n",
      " 64.61538462 56.4516129  66.66666667 52.30769231 54.94505495 55.39568345\n",
      " 56.17977528 58.5106383  52.17391304 53.62318841 62.71186441 59.45945946\n",
      " 55.55555556]\n",
      "***\n",
      "precision:  54.49222997610388\n",
      "\n",
      "\n",
      "recall:  [52.5  66.25 55.    0.   36.25 78.75 52.5  43.75 55.   42.5  62.5  96.25\n",
      " 62.5  68.75 75.   46.25 46.25 82.5  62.5 ]\n",
      "***\n",
      "recall:  57.10526315789474\n"
     ]
    }
   ],
   "source": [
    "print('Test')\n",
    "test_y_true , test_y_pred = lvq.test(dataset.test_data_shuffle, dataset.test_label_shuffle)\n",
    "print(100*'/')\n",
    "print('\\n')\n",
    "print('Train')\n",
    "train_y_true , train_y_pred = lvq.test(dataset.train_data_shuffle, dataset.train_label_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-serve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "specific-ireland",
   "metadata": {},
   "source": [
    "## Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "prostate-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_img(test_data, amount= 0.1):\n",
    "    new_test = []\n",
    "    for img in test_data:\n",
    "        temp_img = copy.deepcopy(img)\n",
    "        sp = random_noise(temp_img, mode = 's&p', amount = amount)\n",
    "        new_test.append(sp)\n",
    "        \n",
    "    return np.array(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "likely-stable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1520, 10000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_10_noise = noise_img(dataset.train_data_shuffle, amount= 0.1)\n",
    "new_train_10_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "vertical-energy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1520, 10000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_20_noise = noise_img(dataset.train_data_shuffle, amount= 0.2)\n",
    "new_train_20_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "lovely-perspective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with 10% noise\n",
      "accuracy:  52.69736842105262\n",
      "\n",
      "\n",
      "precision:  [ 59.15492958  94.          76.78571429   0.          52.\n",
      "  50.          75.55555556  68.18181818  45.28301887  52.38095238\n",
      "  68.91891892 100.          51.64835165  56.98924731  63.04347826\n",
      "  83.87096774  57.62711864  83.33333333  16.90544413]\n",
      "***\n",
      "precision:  60.8252025702531\n",
      "\n",
      "\n",
      "recall:  [52.5  58.75 53.75  0.   32.5  80.   42.5  37.5  60.   41.25 63.75 57.5\n",
      " 58.75 66.25 72.5  32.5  42.5  75.   73.75]\n",
      "***\n",
      "recall:  52.69736842105264\n"
     ]
    }
   ],
   "source": [
    "print('Train with 10% noise')\n",
    "test_y_true , test_y_pred = lvq.test(new_train_10_noise, dataset.train_label_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "valued-hollywood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with 20% noise\n",
      "accuracy:  40.19736842105263\n",
      "\n",
      "\n",
      "precision:  [ 84.61538462 100.          88.63636364   0.          70.58823529\n",
      "  53.06122449 100.         100.          47.82608696  75.\n",
      "  82.           0.          60.81081081  76.5625      84.74576271\n",
      " 100.          89.65517241  90.69767442   8.91719745]\n",
      "***\n",
      "precision:  69.11139014734135\n",
      "\n",
      "\n",
      "recall:  [41.25 18.75 48.75  0.   30.   65.   31.25 20.   55.   37.5  51.25  0.\n",
      " 56.25 61.25 62.5  16.25 32.5  48.75 87.5 ]\n",
      "***\n",
      "recall:  40.19736842105262\n"
     ]
    }
   ],
   "source": [
    "print('Train with 20% noise')\n",
    "test_y_true , test_y_pred = lvq.test(new_train_20_noise, dataset.train_label_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-christianity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
